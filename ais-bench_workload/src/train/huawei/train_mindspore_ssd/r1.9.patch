diff -Nur origin/eval.py code/eval.py
--- origin/eval.py	2022-09-26 09:51:49.660000000 +0800
+++ code/eval.py	2022-09-26 09:51:49.668000000 +0800
@@ -58,6 +58,16 @@
     mAP = apply_eval(eval_param_dict)
     print("\n========================================\n")
     print(f"mAP: {mAP}")
+    ACC_DIR = os.getenv("RESULT_PATH")
+    if ACC_DIR is None:
+        print("Warning: The environment variable 'RESULT_PATH' is not set. ")
+    elif not os.path.isdir(ACC_DIR):
+        print("Warning: The environment variable 'RESULT_PATH' is not a valid directory. ")
+    else:
+        print("ACC_DIR:", ACC_DIR)
+        ACC_LOG = os.path.join(ACC_DIR, "eval_acc.log")
+        with open(ACC_LOG, 'w') as f:
+            f.write("{}".format(mAP))
 
 @moxing_wrapper()
 def eval_net():
diff -Nur origin/train.py code/train.py
--- origin/train.py	2022-09-26 09:51:49.664000000 +0800
+++ code/train.py	2022-09-26 09:51:49.668000000 +0800
@@ -16,6 +16,7 @@
 """Train SSD and get checkpoint files."""
 
 import os
+import time
 import mindspore as ms
 import mindspore.nn as nn
 from mindspore import Tensor
@@ -36,6 +37,12 @@
 from src.model_utils.moxing_adapter import moxing_wrapper
 
 set_seed(1)
+try:
+   import ais_utils
+except ImportError:
+   ais_utils_is_existed = False
+else:
+   ais_utils_is_existed = True
 
 def ssd_model_build():
     if config.model_name == "ssd300":
@@ -198,7 +205,31 @@
         print("In sink mode, one epoch return a loss.")
         dataset_sink_mode = True
     print("Start train SSD, the first epoch will be slower because of the graph compilation.")
+    model.build(dataset, sink_size=dataset.get_dataset_size(), epoch=config.epoch_size)
+
+    if ais_utils_is_existed:
+        start_time = ais_utils.get_datatime()
+    else:
+        start_time = time.time()
     model.train(config.epoch_size, dataset, callbacks=callback, dataset_sink_mode=dataset_sink_mode)
+    all_data_sum = config.epoch_size * dataset.get_dataset_size() * config.batch_size
+    if ais_utils_is_existed:
+        end_time = ais_utils.get_datatime()
+        throughput_rate = ais_utils.calc_throughput_rate(all_data_sum, start_time, end_time)
+    else:
+        end_time = time.time()
+        throughput_rate = all_data_sum / (end_time - start_time)
+
+    rank_id = int(os.getenv('RANK_ID'))
+    THROUGHPUT_DIR = os.getenv("RESULT_PATH")
+    if THROUGHPUT_DIR is None:
+        print("Warning: The environment variable 'RESULT_PATH' is not set. ")
+    elif not os.path.isdir(THROUGHPUT_DIR):
+        print("Warning: The environment variable 'RESULT_PATH' is not a valid directory. ")
+    else:
+        THROUGHPUT_LOG = os.path.join(THROUGHPUT_DIR, "throughput_rank_{}".format(rank_id))
+        with open(THROUGHPUT_LOG, 'w') as f:
+            f.write("{}".format(throughput_rate))
 
 if __name__ == '__main__':
     train_net()
