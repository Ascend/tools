diff -Nur origin/eval.py code/eval.py
--- origin/eval.py	2023-03-27 15:53:34.360000000 +0800
+++ code/eval.py	2023-03-27 15:53:34.388000000 +0800
@@ -82,6 +82,15 @@
     # eval model
     res = model.eval(dataset)
     print("result:", res, "ckpt=", config.checkpoint_file_path)
+    ACC_DIR = os.getenv("RESULT_PATH")
+    if ACC_DIR is None:
+        print("Warning: The environment variable 'RESULT_PATH' is not set. ")
+    elif not os.path.isdir(ACC_DIR):
+        print("Warning: The environment variable 'RESULT_PATH' is not a valid directory. ")
+    else:
+        ACC_LOG = os.path.join(ACC_DIR, "eval_acc.log")
+        with open(ACC_LOG, 'w') as f:
+            f.write("{}".format(res['top_1_accuracy']))

 if __name__ == '__main__':
     eval_net()
diff -Nur origin/train.py code/train.py
--- origin/train.py	2023-03-27 15:53:34.364000000 +0800
+++ code/train.py	2023-03-27 15:53:34.388000000 +0800
@@ -14,7 +14,7 @@
 # ============================================================================
 """train resnet."""
 import os
-
+import time
 import mindspore as ms
 import mindspore.nn as nn
 from mindspore.train.train_thor import ConvertModelUtils
@@ -31,6 +31,12 @@
 from src.model_utils.config import config
 from src.model_utils.moxing_adapter import moxing_wrapper
 from src.model_utils.device_adapter import get_device_num
+try:
+   import ais_utils
+except ImportError:
+   ais_utils_is_existed = False
+else:
+   ais_utils_is_existed = True

 ms.set_seed(1)

@@ -197,6 +203,7 @@
         ms.load_param_into_net(opt, resume_param)
         config.logger.info('resume train from epoch: %s', config.start_epoch)

+
     # define callbacks
     loss_cb = LossCallBack(config.epoch_size, config.logger, lr, per_print_time=10)
     resume_cb = ResumeCallback(config.start_epoch)
@@ -217,15 +224,36 @@
                                       cache_session_id=config.cache_session_id)
         eval_cb = eval_callback(model, config, eval_dataset)
         cb.append(eval_cb)
-
+    model.build(dataset, None, sink_size=dataset.get_dataset_size(), epoch=config.epoch_size)
     # train model
     if config.net_name == "se-resnet50":
         config.epoch_size = config.train_epoch_size
     dataset_sink_mode = (not config.parameter_server) and target != "CPU"
     config.logger.save_args(config)
+    if ais_utils_is_existed:
+        start_time = ais_utils.get_datatime()
+    else:
+        start_time = time.time()
     model.train(config.epoch_size - config.start_epoch, dataset, callbacks=cb,
                 sink_size=dataset.get_dataset_size(), dataset_sink_mode=dataset_sink_mode)
-
+    all_data_sum = step_size * config.batch_size * config.epoch_size
+    if ais_utils_is_existed:
+        end_time = ais_utils.get_datatime()
+        throughput_rate = ais_utils.calc_throughput_rate(all_data_sum, start_time, end_time)
+    else:
+        end_time = time.time()
+        throughput_rate = all_data_sum/(end_time - start_time)
+
+    rank_id = int(os.getenv('RANK_ID'))
+    THROUGHPUT_DIR = os.getenv("RESULT_PATH")
+    if THROUGHPUT_DIR is None:
+        print("Warning: The environment variable 'RESULT_PATH' is not set. ")
+    elif not os.path.isdir(THROUGHPUT_DIR):
+        print("Warning: The environment variable 'RESULT_PATH' is not a valid directory. ")
+    else:
+        THROUGHPUT_LOG = os.path.join(THROUGHPUT_DIR, "throughput_rank_{}".format(rank_id))
+        with open(THROUGHPUT_LOG, 'w') as f:
+            f.write("{}".format(throughput_rate))
     config.logger.info("If run eval and enable_cache Remember to shut down the cache server via \"cache_admin --stop\"")


