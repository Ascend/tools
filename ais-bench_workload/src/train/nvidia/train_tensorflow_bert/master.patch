diff -Nur -x '.git*' origin/run_pretraining.py code/run_pretraining.py
--- origin/run_pretraining.py	2021-09-02 13:52:16.480000000 +0800
+++ code/run_pretraining.py	2021-09-02 13:52:16.488000000 +0800
@@ -22,6 +22,8 @@
 import modeling
 import optimization
 import tensorflow as tf
+import time
+import ais_utils
 
 flags = tf.flags
 
@@ -463,7 +465,13 @@
         max_seq_length=FLAGS.max_seq_length,
         max_predictions_per_seq=FLAGS.max_predictions_per_seq,
         is_training=True)
+    start = time.process_time()
     estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)
+    end = time.process_time()
+    data_sum = FLAGS.train_batch_size * FLAGS.num_train_steps
+    throught_rate = ais_utils.calc_throughput_rate(data_sum, (int)(end - start))
+    ais_utils.set_result("training", "throughput_ratio", throught_rate)
+    print("start:{} end:{} batchsize:{} train_steps:{} datasum:{}  start:{} end:{}  duration:{}  throught_rate:{}".format(start, end, FLAGS.train_batch_size, FLAGS.num_train_steps, data_sum, start, end,  (end-start),  throught_rate))
 
   if FLAGS.do_eval:
     tf.logging.info("***** Running evaluation *****")
@@ -485,6 +493,8 @@
         tf.logging.info("  %s = %s", key, str(result[key]))
         writer.write("%s = %s\n" % (key, str(result[key])))
 
+    if "masked_lm_accuracy" in result:
+        ais_utils.set_result("training", "accuracy", result["masked_lm_accuracy"])
 
 if __name__ == "__main__":
   flags.mark_flag_as_required("input_file")
